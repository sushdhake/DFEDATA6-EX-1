{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloAPIs-solution .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVev4ZyNQmkxFXy3asPAES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushdhake/DFEDATA6-EX-1/blob/master/HelloAPIs_solution_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyelf47n-0K-",
        "outputId": "fa7465a8-d04a-4829-927d-72dff99ec8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-vision-computervision\n",
            "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting msrest>=0.5.0\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.23.0)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 368 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
            "Installing collected packages: isodate, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
            "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 isodate-0.6.1 msrest-0.6.21\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "eUnwIdpz_3sF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_key = \"7db033dbbbc141e1af52f567e4c9cc36\"\n",
        "endpoint = \"https://popopopopo.cognitiveservices.azure.com/\""
      ],
      "metadata": {
        "id": "ynMjZJsJAjYM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds= CognitiveServicesCredentials(subscription_key)\n",
        "computervision_client = ComputerVisionClient(endpoint, creds)\n",
        "# API Authentication settings"
      ],
      "metadata": {
        "id": "wl9BxRxxA4bL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseimgurl = 'https://dodokilledplatypus.blob.core.windows.net/images/0000'\n",
        "allurls = []\n",
        "for i in range(3):\n",
        "  filename = baseimgurl + str(i+1) + '.jpeg'\n",
        "  allurls.append(filename)\n",
        "\n",
        "  allurls\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "qlR69DNVBFwh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "\n",
        "for url in allurls:\n",
        "  description_results = computervision_client.describe_image(url)\n",
        "  print(\"Description of remote image: \")\n",
        "  if (len(description_results.captions) == 0):\n",
        "      print(\"No description detected.\")\n",
        "  else:\n",
        "   for caption in description_results.captions:\n",
        "      print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
        "  print('**************************')\n",
        "\n",
        "# Get the captions (descriptions) from the response, with confidence level\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnRrRovE7F1",
        "outputId": "f1845c2e-e39d-44af-fd14-2327d3caff10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Describe an image - remote =====\n",
            "Description of remote image: \n",
            "'a man and woman posing for a picture' with confidence 52.03%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'shape' with confidence 50.39%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'icon' with confidence 96.81%\n",
            "**************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Categorize an Image - remote\n",
        "This example extracts (general) categories from a remote image with a confidence score.\n",
        "'''\n",
        "print(\"===== Categorize an image - remote =====\")\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  categorize_results_remote = computervision_client.analyze_image(url , remote_image_features)\n",
        "  # Print results with confidence score\n",
        "  print(\"Categories from remote image: \")\n",
        "  if (len(categorize_results_remote.categories) == 0):\n",
        "      print(\"No categories detected.\")\n",
        "  else:\n",
        "     for category in categorize_results_remote.categories:\n",
        "         print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
        "  print('**********')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC713G9bI_im",
        "outputId": "b71dd213-3150-4d62-c4ad-8dc654c53ebd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Categorize an image - remote =====\n",
            "Categories from remote image: \n",
            "'people_' with confidence 79.30%\n",
            "**********\n",
            "Categories from remote image: \n",
            "'others_' with confidence 17.58%\n",
            "**********\n",
            "Categories from remote image: \n",
            "'text_sign' with confidence 14.84%\n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tag an Image - remote\n",
        "This example returns a tag (key word) for each thing in the image.\n",
        "'''\n",
        "print(\"===== Tag an image - remote =====\")\n",
        "# Call API with remote image\n",
        "for url in allurls:\n",
        "   tags_result_remote = computervision_client.tag_image(url )\n",
        "\n",
        "   # Print results with confidence score\n",
        "   print(\"Tags in the remote image: \")\n",
        "   if (len(tags_result_remote.tags) == 0):\n",
        "      print(\"No tags detected.\")\n",
        "   else:\n",
        "      for tag in tags_result_remote.tags:\n",
        "           print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
        "      print('*************')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JCzCCcsKvE0",
        "outputId": "c7c7a9e8-9dca-4a3f-8927-41208a0d411d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Tag an image - remote =====\n",
            "Tags in the remote image: \n",
            "'clothing' with confidence 99.70%\n",
            "'person' with confidence 99.32%\n",
            "'human face' with confidence 98.41%\n",
            "'man' with confidence 94.85%\n",
            "'outdoor' with confidence 94.79%\n",
            "'smile' with confidence 92.92%\n",
            "'coat' with confidence 91.53%\n",
            "'text' with confidence 86.89%\n",
            "'jacket' with confidence 84.15%\n",
            "'suit' with confidence 72.94%\n",
            "'posing' with confidence 65.38%\n",
            "'standing' with confidence 63.36%\n",
            "'woman' with confidence 54.82%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'animated cartoon' with confidence 95.96%\n",
            "'animation' with confidence 94.13%\n",
            "'illustration' with confidence 93.42%\n",
            "'clipart' with confidence 90.92%\n",
            "'drawing' with confidence 88.07%\n",
            "'fiction' with confidence 85.87%\n",
            "'cartoon' with confidence 71.44%\n",
            "'anime' with confidence 69.29%\n",
            "'art' with confidence 68.25%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'symbol' with confidence 96.65%\n",
            "'logo' with confidence 95.66%\n",
            "'font' with confidence 93.46%\n",
            "'graphics' with confidence 90.83%\n",
            "'circle' with confidence 90.57%\n",
            "'trademark' with confidence 86.31%\n",
            "'screenshot' with confidence 84.16%\n",
            "'design' with confidence 52.69%\n",
            "*************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Detect Faces - remote\n",
        "This example detects faces in a remote image, gets their gender and age,\n",
        "and marks them with a bounding box.\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"===== Detect Faces - remote =====\")\n",
        "# Get an image with faces\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"faces\"]\n",
        "# Call the API with remote URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  detect_faces_results_remote = computervision_client.analyze_image(url, remote_image_features)\n",
        "\n",
        "  # Print the results with gender, age, and bounding box\n",
        "  print(\"Faces in the remote image: \")\n",
        "  if (len(detect_faces_results_remote.faces) == 0):\n",
        "       print(\"No faces detected.\")\n",
        "  else:\n",
        "     for face in detect_faces_results_remote.faces:\n",
        "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
        "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
        "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
        "        face.face_rectangle.top + face.face_rectangle.height))\n",
        "  print('***********')                                                                    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGHKXTFOe4nP",
        "outputId": "54af8e5a-572f-47d1-cf2e-979d58b03555"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Detect Faces - remote =====\n",
            "Faces in the remote image: \n",
            "'Male' of age 35 at location 159, 37, 200, 78\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n"
          ]
        }
      ]
    }
  ]
}